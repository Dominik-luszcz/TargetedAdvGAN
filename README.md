Targeted Manipulation: Slope-Based Attacks on Financial Time Series Data
(CSCD94 - Summer 2025)

While current machine learning and artificial intelligence research is focused on improving performance, there is a severe lack of concern regarding their security. One main method of attacking deep learning models is through adversarial attacks, which occur when an attacker specifically modifies the input of a model to produce an incorrect result. Adversarial attacks have been deeply investigated in the image domain; however, there is less research in the time series domain and very little for forecasting financial data. To address these concerns, this study aims to build upon previous research on adversarial attacks for time series data by introducing two new slope-based methods aimed to alter the trends of the predicted stock forecast generated by an N-HiTS model. Compared to the normal N-HiTS predictions, the two new slope-based methods, the General Slope Attack and Least-Squares Slope Attack, can manipulate N-HiTS predictions by doubling the slope. These new slope attacks can bypass standard security mechanisms, such as a discriminator that filters real and perturbed inputs, reducing a 4-layered CNN's specificity to 28\% and accuracy to 57\%. Furthermore, the slope based methods were incorporated into a GAN architecture as a means of generating realistic synthetic data, while simultaneously fooling the model. Finally, this paper also proposes a sample malware designed to inject an adversarial attack in the model inference library, proving that ML-security research should not only focus on making the model safe, but also securing the entire pipeline.

Directory layout:
- stock_projection_model: The model to run the NHITS model from pytorch-forecasting for prediction stock adjprc.
- Adversarial_Attacks: Sample scripts to run adversarial attacks on the NHITS model, mainly the new slope attacks, and baseline attacks such as the FGSM, BIM, MI_FGSM, C&W, etc.
- GANS: Purely experimental directory used to familiarize myself with the GAN-architecture. May not be as maintained as other directories.
- Toy_Adversarial_Models: Purely experimental directory used to play around with adversarial architectures and adversarial discriminators.
- TarAdvNet: The Adversarial GAN model used to generate synthetic time series data to fool the NHITS forecasting model.
- Adversarial_Discriminator: The discriminator used to determine whether data generated by the adversarial attacks can pass as real data.
- Sample_Malware: A directory containing a clean and malware-ridden version of the inference files to simulate an adversarial attack in the ML-pipeline
- Weekly_Slides: Weekly slides made during the CSCD94 course to present to my supervisor. This directory also contains the slides used for presentations and my midetem report.


Requirements:
- Found in requirements.txt, created by pipreqs so it may not be 100% accurate nor may it capture every necessary package.