import torch
from ForecastingModel.preprocessing import preprocess
import pandas as pd


def call_model(model, recording):

    features_df, ticker, center_, scale_, adjprc = preprocess(recording)
    days = torch.from_numpy(features_df["adjprc_day"].to_numpy())
    features = torch.from_numpy(features_df.to_numpy())
    features = features.type(torch.float32)
    x_prime = features[:, 0]
    features[:, 0] = (features[:, 0] - center_) / scale_
    features = features[:, :-2]

    lookback_length = model.hparams["context_length"]
    forecast_length = model.hparams["prediction_length"]

    # craft payload
    # payload: (dictionary)
    # 1. encoder_cat -> long (batch_size x n_encoder_time_steps x n_features) -> long tensor of encoded categoricals for encoder
    # 2. encoder_cont -> float tensor of scaled continuous variables for encoder
    # 3. encoder_lengths -> long tensor with lengths of the encoder time series. No entry will be greater than n_encoder_time_steps
    # 4. encoder_target -> if list, each entry for a different target. float tensor with unscaled continous target or encoded categorical target, list of tensors for multiple targets
    # 5. decoder_cat -> long tensor of encoded categoricals for decoder
    # 6. decoder_cont -> float tensor of scaled continuous variables for decoder
    # 7. decoder_lengths -> long tensor with lengths of the decoder time series. No entry will be greater than n_decoder_time_steps
    # 8. decoder_target -> if list, with each entry for a different target. float tensor with unscaled continous target or encoded categorical target for decoder - this corresponds to first entry of y, list of tensors for multiple targets
    # 9. target_scale -> if list, with each entry for a different target. parameters used to normalize the target. Typically these are mean and standard deviation. Is list of tensors for multiple targets.

    encoder_batches = []
    encoder_categorical_batches = []
    decoder_batches = []
    decoder_categorical_batches = []
    time_idx = []
    encoder_targets = []
    decoder_targets = []

    for i in range(
        0, len(features) - lookback_length - forecast_length + 1
    ):  # need to make room for prediction values
        encoder_batches.append(features[i : i + lookback_length, :])
        encoder_categorical_batches.append(days[i : i + lookback_length])
        encoder_targets.append(x_prime[i : i + lookback_length])

        decoder_batches.append(
            features[i + lookback_length : i + lookback_length + forecast_length, :]
        )
        decoder_categorical_batches.append(
            days[i + lookback_length : i + lookback_length + forecast_length]
        )
        decoder_targets.append(
            x_prime[i + lookback_length : i + lookback_length + forecast_length]
        )
        time_idx.append(
            torch.arange(i + lookback_length, i + lookback_length + forecast_length)
        )

    encoder_batches = torch.stack(encoder_batches)
    encoder_batches = encoder_batches.requires_grad_()
    encoder_categorical_batches = torch.stack(encoder_categorical_batches).unsqueeze(-1)

    encoder_targets = torch.stack(encoder_targets)

    decoder_batches = torch.stack(decoder_batches)
    decoder_categorical_batches = torch.stack(decoder_categorical_batches).unsqueeze(-1)

    decoder_targets = torch.stack(decoder_targets)

    # will need to batch this further
    payload = {
        "encoder_cat": encoder_categorical_batches,  # this should be the categorical features from the lookback period
        "encoder_cont": encoder_batches,  # this should be the continous features from the lookback period
        "encoder_lengths": torch.tensor(
            [lookback_length]
        ),  # should be length of lookback period
        "encoder_target": encoder_targets,  # should be the target variable of teh lookback period (adjprc)
        "decoder_cat": decoder_categorical_batches,  # should be the categorical features of the next forecast_length features
        "decoder_cont": decoder_batches,  # should be the continous features of the next forecast_length features
        "decoder_lengths": torch.tensor(
            [forecast_length]
        ),  # should be the length of the prediction
        "decoder_target": decoder_targets,  # should be the ground truths for the next forecast_length adjprc
        "target_scale": torch.tensor([center_, scale_]).unsqueeze(
            0
        ),  # should be the center and scale of the robust scalar
        "decoder_time_idx": torch.stack(time_idx),
    }

    """
    output[0] = tensor of shape [2, 50, 7] # 7 because we have 7 quantiles, so 2 batches, 50 forward proj, 7 quantiles, quantile 0.5 is the prediction so it would be index 3 for the prediction
    output[1] = tensor of shape [2, lookback_length, 1] # 2 batches, lookback_length for the lookback
    output[2] = tuple of length 4: 
        output[2][0]: tensor of shape [2, lookback_length, 1] # forecasts
        output[2][1]: tensor of shape [2, lookback_length, 1]
        output[2][2]: tensor of shape [2, lookback_length, 1]
        output[2][3]: tensor of shape [2, lookback_length, 1]
    output[3] = tuple of length 4:
        output[3][0]: tensor of shape [2, 50, 7] # backcasts
        output[3][1]: tensor of shape [2, 50, 7]
        output[3][2]: tensor of shape [2, 50, 7]
        output[3][3]: tensor of shape [2, 50, 7]

    """

    output = model(payload)
    time_idx = torch.concatenate(time_idx)

    return output, time_idx, ticker, adjprc


def get_predictions(outputs, time_idx, lookback_length):
    predictions = outputs[0][:, :, 3].flatten()
    time_idx = time_idx - lookback_length
    max_time = max(time_idx) + 1  # -lookback_length so we start at 0
    bin_sums = torch.zeros(max_time).scatter_add(dim=0, index=time_idx, src=predictions)
    bin_counts = torch.zeros(max_time).scatter_add(
        dim=0, index=time_idx, src=torch.ones_like(predictions)
    )
    final_predictions = bin_sums / bin_counts
    return final_predictions


def predict(model, recording):
    with torch.no_grad():
        outputs, time_idx, ticker, adjprc = call_model(model, recording)
        predictions = get_predictions(
            outputs, time_idx, model.hparams["context_length"]
        )
    return predictions, ticker, adjprc
