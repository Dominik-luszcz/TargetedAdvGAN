import torch
import pytorch_forecasting as pf

def attack(timeSeriesDataset: pf.TimeSeriesDataSet, model, iterations = 10, epsilon = 1, target_direction=1, c = 5, d = 2):
    adjprc = timeSeriesDataset.data["reals"]
    adjprc = adjprc.float()
    alpha = 1.5 * epsilon / iterations

    x_i = adjprc.clone()
    dataset = timeSeriesDataset
    for i in range(iterations):
        x_i = x_i.requires_grad_()
        x_i = x_i.float()
        model.zero_grad()
        dataset.data["reals"] = x_i

        predictions = model.predict(dataset, return_x=True, mode="raw", trainer_kwargs=dict(accelerator="cpu"))

        output, time_idx = call_model(x_i, days)

        predictions = output[0][:, :, 3].flatten()

        time_idx = time_idx - self.lookback_length
        max_time = max(time_idx) + 1 # -self.lookback_length so we start at 0
        bin_sums = torch.zeros(max_time).scatter_add(dim=0, index=time_idx, src=predictions)
        bin_counts = torch.zeros(max_time).scatter_add(dim=0, index=time_idx, src=torch.ones_like(predictions))
        predictions = bin_sums / bin_counts

        slope = (predictions[-1] - predictions[0]) / len(predictions)
        if target_direction != 0:
            target_direction = target_direction * -1
            loss = c * torch.exp(target_direction * d * slope)
        else:
            loss = c * (slope ** 2)

        loss = loss.float()

        loss.backward()

        with torch.no_grad():
            grad = x_i.grad.data
            sign_grad = grad.sign()
            noise = alpha * sign_grad
            attack_x_i = x_i - noise
            attack_x_i = torch.clamp(attack_x_i, adjprc - epsilon, adjprc + epsilon)
            x_i = attack_x_i

        x_i.detach()
