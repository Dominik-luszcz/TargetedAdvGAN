import torch
import pandas as pd
import numpy as np
import pytorch_forecasting as pf

'''
Compute the ema based on the pandas formula in their documentation (when adjust=False)
'''
def exponential_moving_average(adjprc: torch.Tensor, span: int):

    alpha = 2.0 / (span + 1.0)

    ema = torch.zeros_like(adjprc) 
    ema[0] = adjprc[0]

    # formula taken from the pandas definition
    for i in range(1, len(adjprc)):
        ema[i] = (1 - alpha) * adjprc[i-1] + alpha * adjprc[i]

    return ema

def feature_generation(adjprc: torch.Tensor):

    weight5 = torch.ones((1,1,5))/5
    weight10 = torch.ones((1,1,10))/10
    weight20 = torch.ones((1,1,20))/20
    rolling_mean5 = torch.nn.functional.conv1d(adjprc.unsqueeze(0).unsqueeze(0), weight5, stride=1)

    rolling_mean10 = torch.nn.functional.conv1d(adjprc.unsqueeze(0).unsqueeze(0), weight10, stride=1)

    rolling_mean20 = torch.nn.functional.conv1d(adjprc.unsqueeze(0).unsqueeze(0), weight20, stride=1)

    # stdevs: Variance = E[x^2] - E[x]^2
    # so E[x] = rolling_meanX => E[x]^2 = rolling_meanX ^ 2
    rollingExp_mean5 = torch.nn.functional.conv1d(adjprc.unsqueeze(0).unsqueeze(0) ** 2, weight5, stride=1)
    rollingExp_mean10 = torch.nn.functional.conv1d(adjprc.unsqueeze(0).unsqueeze(0) ** 2, weight10, stride=1)
    rollingExp_mean20 = torch.nn.functional.conv1d(adjprc.unsqueeze(0).unsqueeze(0) ** 2, weight20, stride=1)

    rolling_stdev5 = torch.sqrt(torch.clip(rollingExp_mean5 - rolling_mean5**2 + 1e-06, min=0))
    rolling_stdev10 = torch.sqrt(torch.clip(rollingExp_mean10 - rolling_mean10**2 + 1e-06, min=0))
    rolling_stdev20 = torch.sqrt(torch.clip(rollingExp_mean20 - rolling_mean20**2 + 1e-06, min=0))
    # but we have padding and the model fills the first x values with something (either adjprc or mean rolling_stdev) so we have to fix that
    rolling_mean5 = rolling_mean5.squeeze(0).squeeze(0)
    rolling_mean5 = torch.cat([adjprc[:4], rolling_mean5])
    rolling_stdev5 = rolling_stdev5.squeeze(0).squeeze(0)
    rolling_stdev5 = torch.cat([torch.full(size=[4], fill_value=torch.mean(rolling_stdev5.squeeze(0).squeeze(0)).item()), rolling_stdev5])

    rolling_mean10 = rolling_mean10.squeeze(0).squeeze(0)
    rolling_mean10 = torch.cat([adjprc[:9], rolling_mean10])
    rolling_stdev10 = rolling_stdev10.squeeze(0).squeeze(0)
    rolling_stdev10 = torch.cat([torch.full(size=[9], fill_value=torch.mean(rolling_stdev10.squeeze(0).squeeze(0)).item()), rolling_stdev10])

    rolling_mean20 = rolling_mean20.squeeze(0).squeeze(0)
    rolling_mean20 = torch.cat([adjprc[:19], rolling_mean20])
    rolling_stdev20 = rolling_stdev20.squeeze(0).squeeze(0)
    rolling_stdev20 = torch.cat([torch.full(size=[19], fill_value=torch.mean(rolling_stdev20.squeeze(0).squeeze(0)).item()), rolling_stdev20])

    # log returns 
    log_returns = torch.log(adjprc[1:]/adjprc[:-1]) 
    log_returns = torch.cat([torch.tensor([0.0]), log_returns]) 

    # ROC (percetn change of 5)
    roc5 = (adjprc[5:] - adjprc[:-5]) / adjprc[:-5]
    roc5 = torch.cat([torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0]), roc5])

    # exponential moving averages
    ema_5 = exponential_moving_average(adjprc=adjprc, span=5)
    ema_10 = exponential_moving_average(adjprc=adjprc, span=10)
    ema_20 = exponential_moving_average(adjprc=adjprc, span=20)

    features = torch.stack([rolling_mean5, rolling_mean10, rolling_mean20, 
                            rolling_stdev5, rolling_stdev10, rolling_stdev20, 
                            log_returns, roc5, ema_5, ema_10, ema_20], dim=1)


    # Because we are doing 1 recording at a time, the standard scalar for teh features (not target) are just the mean and stdev of the recording
    # Similarly, the quantiles are the same for the target for the robust scalar for adjprc

    avg = torch.mean(features, dim=0)
    stdev = torch.std(features, dim=0)

    features = (features - avg) / stdev

    # median = torch.median(adjprc, dim=0).values
    # q75 = torch.quantile(adjprc, q=0.75, dim=0)
    # q25 = torch.quantile(adjprc, q=0.25, dim=0)
    # #adjprc = (adjprc - median) / (q75 - q25)

    # scale_ = q75 - q25
    # center_ = median

    center_ = np.median(adjprc.detach().numpy())
    scale_ = (np.quantile(adjprc.detach().numpy(), q=0.75) - np.quantile(adjprc.detach().numpy(), q=0.25)) / 2

    features = torch.hstack([adjprc.unsqueeze(-1), features])

    return features, scale_, center_

def preprocess(recording):
    df = pd.read_csv(recording)

    adjprc = torch.from_numpy(df["adjprc"].values).float()
    features, center_, scale_ = feature_generation(adjprc)

    columns = ["adjprc", "rolling_mean5", "rolling_mean10", "rolling_mean20", 
                        "rolling_stdev5", "rolling_stdev10", "rolling_stdev20", 
                        "log_returns", "roc5", "ema_5", "ema_10", "ema_20"]
    
    features_df = pd.DataFrame(features.detach().cpu().numpy(), columns=columns)
    
    # add the specific day of the week as a feature, as stock 
    # markets tend to have a lull on Monday and improve as the week goes on
    df["date"] = pd.to_datetime(df["date"])
    features_df["adjprc_day"] = (df["date"].dt.day_of_week).astype(int)


    features_df["time_idx"] = np.arange(len(df))

    return features_df, df["ticker"].unique(), center_, scale_, adjprc

    #features_df["ticker"] = df["ticker"]

    # dataset = pf.TimeSeriesDataSet(
    #     features_df,
    #     group_ids=["ticker"],
    #     target="adjprc",
    #     time_idx="time_idx",
    #     max_encoder_length=100,
    #     min_prediction_length=20,
    #     max_prediction_length=20,
    #     time_varying_known_categoricals=["adjprc_day"],
    #     time_varying_unknown_reals=["adjprc","rolling_mean5",
    #                                 "rolling_mean10","rolling_mean20",
    #                                 "rolling_stdev5","rolling_stdev10","rolling_stdev20",
    #                                 "log_returns", "roc5", "ema_5", "ema_10", "ema_20"],
    #     target_normalizer=pf.GroupNormalizer(groups=["ticker"], method="robust"),
    # )

    # return dataset

    

    